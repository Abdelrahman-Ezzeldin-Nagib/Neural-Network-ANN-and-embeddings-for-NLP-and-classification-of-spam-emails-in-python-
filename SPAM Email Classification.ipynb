{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klez the virus that won t die already the most...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in adding cream to spaghetti carbonara which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  label\n",
       "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1  martin a posted tassos papadopoulos the greek ...      0\n",
       "2  man threatens explosion in moscow thursday aug...      0\n",
       "3  klez the virus that won t die already the most...      0\n",
       "4   in adding cream to spaghetti carbonara which ...      0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/ozlerhakan/spam-or-not-spam-dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('E:/Z-Machine Learning/My Work/DataSets/SPAM Email/spam_or_not_spam.csv')\n",
    "#data = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>well i don t think china could force yahoo to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>new account for zzzz URL adult club offers fre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>on mon NUMBER oct NUMBER bitbitch URL wrote i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>url URL date not supplied img URL the t mobile...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>on NUMBER sep NUMBER at NUMBER NUMBER geege sc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>the famous ebay marketing e course learn to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>url URL date NUMBER NUMBER NUMBERtNUMBER NUMBE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>sl snip sl misc rants about finding jobs java...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>on tue aug NUMBER NUMBER at NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>once upon a time alvie wrote this is only the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "618   well i don t think china could force yahoo to ...      0\n",
       "2961  new account for zzzz URL adult club offers fre...      1\n",
       "905   on mon NUMBER oct NUMBER bitbitch URL wrote i ...      0\n",
       "2211  url URL date not supplied img URL the t mobile...      0\n",
       "509   on NUMBER sep NUMBER at NUMBER NUMBER geege sc...      0\n",
       "...                                                 ...    ...\n",
       "2998   the famous ebay marketing e course learn to s...      1\n",
       "2375  url URL date NUMBER NUMBER NUMBERtNUMBER NUMBE...      0\n",
       "429    sl snip sl misc rants about finding jobs java...      0\n",
       "208   on tue aug NUMBER NUMBER at NUMBER NUMBER NUMB...      0\n",
       "1272  once upon a time alvie wrote this is only the ...      0\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "col = 'label'\n",
    "x = df.drop(col,axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for i in df['email']:\n",
    "    text.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/guttiparameswararao/spam-email-classification\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(text)\n",
    "sequences = tokenizer.texts_to_sequences(text)\n",
    "#sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = y\n",
    "x_train=sequences[:2000]\n",
    "y_train=label[:2000]\n",
    "x_test=sequences[2000:]\n",
    "y_test=label[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20\n",
    "from keras import preprocessing\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 20, 8)             16000     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 16,161\n",
      "Trainable params: 16,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1600 samples, validate on 400 samples\n",
      "Epoch 1/30\n",
      "  32/1600 [..............................] - ETA: 2s - loss: 0.6933 - acc: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman Ezz\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600/1600 [==============================] - 0s 79us/step - loss: 0.6288 - acc: 0.8069 - val_loss: 0.5575 - val_acc: 0.8475\n",
      "Epoch 2/30\n",
      "1600/1600 [==============================] - 0s 33us/step - loss: 0.4912 - acc: 0.8344 - val_loss: 0.4162 - val_acc: 0.8475\n",
      "Epoch 3/30\n",
      "1600/1600 [==============================] - 0s 32us/step - loss: 0.3730 - acc: 0.8344 - val_loss: 0.3224 - val_acc: 0.8475\n",
      "Epoch 4/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.3031 - acc: 0.8456 - val_loss: 0.2702 - val_acc: 0.8700\n",
      "Epoch 5/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.2517 - acc: 0.8819 - val_loss: 0.2274 - val_acc: 0.8975\n",
      "Epoch 6/30\n",
      "1600/1600 [==============================] - 0s 30us/step - loss: 0.2070 - acc: 0.9125 - val_loss: 0.1903 - val_acc: 0.9250\n",
      "Epoch 7/30\n",
      "1600/1600 [==============================] - 0s 30us/step - loss: 0.1697 - acc: 0.9269 - val_loss: 0.1604 - val_acc: 0.9500\n",
      "Epoch 8/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.1398 - acc: 0.9463 - val_loss: 0.1377 - val_acc: 0.9550\n",
      "Epoch 9/30\n",
      "1600/1600 [==============================] - 0s 31us/step - loss: 0.1171 - acc: 0.9594 - val_loss: 0.1186 - val_acc: 0.9600\n",
      "Epoch 10/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0994 - acc: 0.9625 - val_loss: 0.1043 - val_acc: 0.9625\n",
      "Epoch 11/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0862 - acc: 0.9688 - val_loss: 0.0924 - val_acc: 0.9650\n",
      "Epoch 12/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0754 - acc: 0.9737 - val_loss: 0.0823 - val_acc: 0.9700\n",
      "Epoch 13/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0668 - acc: 0.9775 - val_loss: 0.0754 - val_acc: 0.9725\n",
      "Epoch 14/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0598 - acc: 0.9812 - val_loss: 0.0700 - val_acc: 0.9725\n",
      "Epoch 15/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0542 - acc: 0.9831 - val_loss: 0.0653 - val_acc: 0.9750\n",
      "Epoch 16/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0495 - acc: 0.9837 - val_loss: 0.0614 - val_acc: 0.9800\n",
      "Epoch 17/30\n",
      "1600/1600 [==============================] - 0s 27us/step - loss: 0.0451 - acc: 0.9844 - val_loss: 0.0584 - val_acc: 0.9825\n",
      "Epoch 18/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0416 - acc: 0.9875 - val_loss: 0.0558 - val_acc: 0.9825\n",
      "Epoch 19/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0386 - acc: 0.9875 - val_loss: 0.0538 - val_acc: 0.9825\n",
      "Epoch 20/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0361 - acc: 0.9875 - val_loss: 0.0513 - val_acc: 0.9825\n",
      "Epoch 21/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0336 - acc: 0.9894 - val_loss: 0.0502 - val_acc: 0.9850\n",
      "Epoch 22/30\n",
      "1600/1600 [==============================] - 0s 27us/step - loss: 0.0314 - acc: 0.9894 - val_loss: 0.0495 - val_acc: 0.9850\n",
      "Epoch 23/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0295 - acc: 0.9900 - val_loss: 0.0477 - val_acc: 0.9850\n",
      "Epoch 24/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0277 - acc: 0.9900 - val_loss: 0.0475 - val_acc: 0.9850\n",
      "Epoch 25/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0261 - acc: 0.9894 - val_loss: 0.0465 - val_acc: 0.9850\n",
      "Epoch 26/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0247 - acc: 0.9906 - val_loss: 0.0463 - val_acc: 0.9850\n",
      "Epoch 27/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0232 - acc: 0.9925 - val_loss: 0.0455 - val_acc: 0.9850\n",
      "Epoch 28/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0219 - acc: 0.9925 - val_loss: 0.0455 - val_acc: 0.9850\n",
      "Epoch 29/30\n",
      "1600/1600 [==============================] - 0s 29us/step - loss: 0.0205 - acc: 0.9944 - val_loss: 0.0461 - val_acc: 0.9825\n",
      "Epoch 30/30\n",
      "1600/1600 [==============================] - 0s 28us/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0451 - val_acc: 0.9800\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import Embedding\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 8, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
